{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# silent warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import mlflow\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# import uuid\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# class TrainingSetUp:\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         self.id = kwargs.get('id', str(uuid.uuid4()))\n",
    "#         self.created_at = kwargs.get('created_at', datetime.now())\n",
    "#         self.updated_at = kwargs.get('updated_at', datetime.now())\n",
    "        \n",
    "#         if isinstance(self.created_at, str):\n",
    "#             self.created_at = datetime.strptime(self.created_at, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "#         for key, value in kwargs.items():\n",
    "#             setattr(self, key, value)\n",
    "\n",
    "#         self.X_train = self.X_test = self.y_train = self.y_test = None\n",
    "#         self.y_pred = self.y_pred_proba = self.y_pred_proba_train = None\n",
    "#         self.y_pred_train = self.y_pred_proba_test = self.y_pred_test = None\n",
    "#         self.__pipeline = self.__model = self.__grid_search = None\n",
    "\n",
    "#     def load_data(self):\n",
    "#         self.data = pd.read_csv(self.data_path)\n",
    "#         self.X = self.data.drop('target', axis=1)\n",
    "#         self.y = self.data['target']\n",
    "\n",
    "#     def split_data(self, test_size=0.2, random_state=42):\n",
    "#         self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "#             train_test_split(self.X, self.y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "#     def pipeline(self):\n",
    "#         if hasattr(self, 'scalers') and hasattr(self, 'model'):\n",
    "#             self.__pipeline = Pipeline([\n",
    "#                 ('scaler', self.scalers),\n",
    "#                 ('model', self.model)\n",
    "#             ])\n",
    "#         else:\n",
    "#             raise AttributeError('scalers and model must be defined')\n",
    "\n",
    "#     def grid_search(self):\n",
    "#         if self.__pipeline is None:\n",
    "#             self.pipeline()\n",
    "#         requires = ['param_grid', 'cv', 'scoring']\n",
    "#         if all(hasattr(self, k) for k in requires):\n",
    "#             self.__grid_search = GridSearchCV(self.__pipeline,\n",
    "#                                               self.param_grid,\n",
    "#                                               cv=self.cv,\n",
    "#                                               scoring=self.scoring)\n",
    "#         else:\n",
    "#             missing = [k for k in requires if not hasattr(self, k)]\n",
    "#             raise AttributeError(f'{\", \".join(missing)} must be defined')\n",
    "\n",
    "# class TrainModel(TrainingSetUp):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.__mlflow_uri = None\n",
    "#         self.__mlflow_metaData = None\n",
    "#         mlflow_info = kwargs.get('mlflow', {})\n",
    "#         self.setup_mlflow(mlflow_info.get('exp_name'), mlflow_info.get('artifact_uri'))\n",
    "#         data_path = kwargs.get('data_path')\n",
    "#         if data_path:\n",
    "#             self.load_data(data_path)\n",
    "\n",
    "#     def setup_mlflow(self, exp_name=None, artifact_uri=None):\n",
    "#         if exp_name is None:\n",
    "#             exp_name = f'mlflow_{self.id}'\n",
    "        \n",
    "#         os.makedirs(\"./mlruns\", exist_ok=True)\n",
    "#         default_uri = f'./mlruns/{exp_name}'\n",
    "#         tracking_uri = os.getenv('MLFLOW_TRACKING_URI_TRAIN', default_uri)\n",
    "#         mlflow.set_tracking_uri(tracking_uri)\n",
    "#         mlflow.set_experiment(exp_name)\n",
    "#         self.__mlflow_uri = tracking_uri\n",
    "\n",
    "#         if artifact_uri:\n",
    "#             mlflow.set_artifact_uri(artifact_uri)\n",
    "\n",
    "#     def train(self):\n",
    "#         with mlflow.start_run():\n",
    "#             if self.__grid_search is None:\n",
    "#                 self.grid_search()\n",
    "            \n",
    "#             self.__grid_search.fit(self.X_train, self.y_train)\n",
    "#             self.__model = self.__grid_search.best_estimator_\n",
    "\n",
    "#             # Log parameters\n",
    "#             mlflow.log_params(self.__grid_search.best_params_)\n",
    "\n",
    "#             # Log metrics\n",
    "#             mlflow.log_metric(\"best_score\", self.__grid_search.best_score_)\n",
    "\n",
    "#             # Log model\n",
    "#             mlflow.sklearn.log_model(self.__model, \"model\")\n",
    "\n",
    "#             # Make predictions\n",
    "#             self.y_pred = self.__model.predict(self.X_test)\n",
    "#             self.y_pred_proba = self.__model.predict_proba(self.X_test)\n",
    "\n",
    "#             # Log additional metrics (you can add more as needed)\n",
    "#             from sklearn.metrics import accuracy_score, f1_score\n",
    "#             accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "#             f1 = f1_score(self.y_test, self.y_pred, average='weighted')\n",
    "#             mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#             mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "#     def evaluate(self):\n",
    "#         # Add your evaluation logic here\n",
    "#         pass\n",
    "\n",
    "#     def save_model(self, path):\n",
    "#         if self.__model is None:\n",
    "#             raise Exception(\"Model has not been trained yet\")\n",
    "#         mlflow.sklearn.save_model(self.__model, path)\n",
    "\n",
    "#     def load_model(self, path):\n",
    "#         self.__model = mlflow.sklearn.load_model(path)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example usage\n",
    "#     kwargs = {\n",
    "#         'mlflow': {'exp_name': 'my_experiment'},\n",
    "#         'data_path': 'path/to/your/data.csv'\n",
    "#     }\n",
    "\n",
    "#     trainer = TrainModel(**kwargs)\n",
    "#     trainer.load_data()\n",
    "#     trainer.split_data()\n",
    "#     trainer.scalers = StandardScaler()\n",
    "#     trainer.model = RandomForestClassifier()\n",
    "#     trainer.param_grid = {\n",
    "#         'model__n_estimators': [100, 200, 300],\n",
    "#         'model__max_depth': [5, 10, None]\n",
    "#     }\n",
    "#     trainer.cv = 5\n",
    "#     trainer.scoring = 'accuracy'\n",
    "#     trainer.train()\n",
    "#     trainer.evaluate()\n",
    "#     trainer.save_model('path/to/save/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_9172\\3077490805.py\", line 5, in <module>\n",
      "    from ml.training import TrainModel\n",
      "  File \"e:\\amihere\\programmingLessons\\ALX-Backend\\FINAL PROJECT\\TripNYC\\models\\ml\\ml.py\", line 7, in <module>\n",
      "    from base.base_model import BaseModel, Base\n",
      "  File \"e:\\amihere\\programmingLessons\\ALX-Backend\\FINAL PROJECT\\TripNYC\\models\\ml\\..\\base\\__init__.py\", line 3, in <module>\n",
      "    from models.location.borough import Borough\n",
      "ModuleNotFoundError: No module named 'models'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\lenovo\\anaconda3\\envs\\amsVenv\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.model_func import load_config\n",
    "import logging\n",
    "from ml.training import TrainModel\n",
    "from utils.model_func import load_config\n",
    "\n",
    "CONFIG_PATH = 'config.json'\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Starting the training process\")\n",
    "\n",
    "    # Load configuration\n",
    "    \n",
    "    config = load_config(CONFIG_PATH)['MODEL1']\n",
    "    config.update({k: eval(v) if (k == 'scalers' or k=='model') \\\n",
    "                   else v  for k, v in config.items()})\n",
    "\n",
    "    trainer = TrainModel(config.get('MODEL1'))\n",
    "    \n",
    "    trainer.load_data(trainer.data_path)\n",
    "    trainer.split_data()\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    trainer.scalers = StandardScaler()\n",
    "    trainer.model = RandomForestClassifier()\n",
    "    trainer.param_grid = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [5, 10, None]\n",
    "    }\n",
    "    trainer.cv = 5\n",
    "    trainer.scoring = 'accuracy'\n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.evaluate()\n",
    "    trainer.save_model('path/to/save/model')\n",
    "    \n",
    "    logging.info(\"Training process completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlflow': {'exp_name': 'my_experiment'}, 'data_path': 'path/to/your/data.csv', 'scalers': 'StandardScaler()', 'model': 'RandomForestClassifier()', 'param_grid': {'model__n_estimators': [100, 200, 300], 'model__max_depth': [5, 10]}, 'cv': 5, 'scoring': 'accuracy', 'model_path': 'path/to/save/model'}\n",
      "{'mlflow': {'exp_name': 'my_experiment'}, 'data_path': 'path/to/your/data.csv', 'scalers': StandardScaler(), 'model': RandomForestClassifier(), 'param_grid': {'model__n_estimators': [100, 200, 300], 'model__max_depth': [5, 10]}, 'cv': 5, 'scoring': 'accuracy', 'model_path': 'path/to/save/model'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.model_func import load_config\n",
    "\n",
    "config = load_config('../utils/config/ml_config.json')['MODEL1']\n",
    "print(config)\n",
    "config.update({k: eval(v) if (k == 'scalers' or k=='model') else v  for k, v in config.items()})\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random dataset\n",
    "X = np.random.rand(100, 4)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "# Define a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define a grid search\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [5, 10, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    '__name__': ['RandomForestClassifier_1']\n",
    "}\n",
    "\n",
    "# Create a grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5,\n",
    "                           scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Set the experiment name\n",
    "mlflow.set_experiment(\"RandomForest_GridSearch\")\n",
    "# Set the MLflow tracking URI\n",
    "tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "if tracking_uri is None:\n",
    "    os.makedirs(\"./mlruns\", exist_ok=True)\n",
    "    tracking_uri = \"./mlruns\"\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "\n",
    "\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 5)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # Train model (simplified)\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Log metrics\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "\n",
    "    # Log a plot as an artifact\n",
    "    plt.figure()\n",
    "    plt.plot(model.feature_importances_)\n",
    "    plt.title(\"Feature Importances\")\n",
    "    plt.savefig(\"feature_importances.png\")\n",
    "    mlflow.log_artifact(\"feature_importances.png\")\n",
    "\n",
    "    # Log a tag\n",
    "    mlflow.set_tag(\"model_type\", \"random_forest\")\n",
    "\n",
    "    # Log a custom artifact (e.g., feature names)\n",
    "    feature_names = [\"feature1\", \"feature2\", \"feature3\"]\n",
    "    np.savetxt(\"feature_names.txt\", feature_names, fmt='%s')\n",
    "    mlflow.log_artifact(\"feature_names.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
